{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bash script to ingest data\n",
    "# This involves scraping the data from the web and then cleaning up and putting in Weaviate.\n",
    "# ! set -eu\n",
    "# wget -r -A.html https://langchain.readthedocs.io/en/latest/\n",
    "# python3 ingest.py\n",
    "# python3 ingest_examples.py\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "- Installation\n",
    "- LLMs\n",
    "- Prompt Templates\n",
    "- Chains\n",
    "- Agents and Tools\n",
    "- Memory\n",
    "- Document Loaders\n",
    "- Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install 'langchain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 LLMS \n",
    "A generic interface for all LLMs. See all LM providers: https://python.langchain.com/en/latest/modules/models/Ilms/integrations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Lively Socks.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)  # model name=\"text-davinci-003\"\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print (llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write token\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import HuggingFaceHub\n",
    "from langchain import HuggingFaceHub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Prompt Templates\n",
    "LangChain faciliates prompt management and optimization.\n",
    "Normally when you use an LLM in an application, you are not sending user input directly to the LLM. Instead, you need to take the user input and\n",
    "construct a prompt, and only then send that to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'колко стар а?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://huggingface.co/google/flan-t5-xl\n",
    "# note: set \"flan-t5-xxl\" to \"flan-t5-xxl\" and \"temperature\":0.9\n",
    "llm = HuggingFaceHub(repo_id = \"google/flan-t5-xxl\", model_kwargs={\"temperature\":1, \"max_length\":64})\n",
    "\n",
    "llm(\"translate English to Russian: How old are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm( \"Can Barack Obama have a conversation with George Washington?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George Washington died in 1799. Barack Obama was born in 1961. The answer: no.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Question: Can Barack Obama  have a conversation with George Washington?\n",
    "Let's think step by step.\n",
    "Answer: \"\"\"\n",
    "llm (prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"\"\" Question: {question}\n",
    "Let's think step by step.\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate (template=template, input_variables=[ \"question\" ])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Chains\n",
    "Combine LLMs and Prompts in multi-step workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "George Washington died in 1799. Barack Obama was born in 1961. The answer: no.\n"
     ]
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "llm_chain = LLMChain (prompt=prompt, llm=llm)\n",
    "question = \"Can Barack Obama have a conversation with George Washington?\"\n",
    "print(llm_chain. run (question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Agents and Tools\n",
    "   \n",
    "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done.\n",
    "When used correctly agents can be extremely powerful. In order to load agents, you should understand the following concepts:\n",
    "Tool: A function that performs a specific duty. This can be things like: Google Search, Database lookup, Python REPL, other chains.\n",
    "LLM: The language model powering the agent.\n",
    "Agent: The agent to use.\n",
    "Tools: https://python.langchain.com/en/latest/modules/agents/tools.html\n",
    "Agent Types: https://python.langchain.com/en/latest/modules/agents/agents/agent_types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI (temperature=0)\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent (tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the year the film was released and then use the calculator to calculate the power.\n",
      "Action: Wikipedia\n",
      "Action Input: Departed with Leonardo Dicaprio\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Leonardo DiCaprio filmography\n",
      "Summary: Leonardo DiCaprio is an American actor who began his career performing as a child on television. He appeared on the shows The New Lassie (1989) and Santa Barbara (1990) and also had long running roles in the comedy-drama Parenthood (1990) and the sitcom Growing Pains (1991). DiCaprio played Tobias \"Toby\" Wolff opposite Robert De Niro in the biographical coming-of-age drama This Boy's Life in 1993. In the same year, he had a supporting role as a developmentally disabled boy Arnie Grape in What's Eating Gilbert Grape, which earned him nominations for the Academy Award for Best Supporting Actor and the Golden Globe Award for Best Supporting Actor – Motion Picture. In 1995, DiCaprio played the leading roles of an American author Jim Carroll in The Basketball Diaries and the French poet Arthur Rimbaud in Total Eclipse. The following year he played Romeo Montague in the Baz Luhrmann-directed film Romeo + Juliet (1996). DiCaprio starred with Kate Winslet in the James Cameron-directed film Titanic (1997). The film became the highest grossing at the worldwide box-office, and made him famous globally. For his performance as Jack Dawson, he received the MTV Movie Award for Best Male Performance and his first nomination for the Golden Globe Award for Best Actor – Motion Picture Drama.In 2002, DiCaprio played con-artist Frank Abagnale, Jr. opposite Tom Hanks in the Steven Spielberg-directed biographical crime-drama Catch Me If You Can and also starred in the Martin Scorsese-directed historical drama Gangs of New York. He founded his own production company, Appian Way, in 2004. The next two films he starred in were both directed by Scorsese: the Howard Hughes biopic The Aviator (2004) and the crime drama The Departed (2006). For his portrayal of Hughes in the former, DiCaprio won the Golden Globe Award for Best Actor – Motion Picture Drama and garnered his first nomination for the Academy Award for Best Actor.DiCaprio produced the environmental documentary The 11th Hour and the comedy drama Gardener of Eden in 2007. The following year, he reunited with Kate Winslet in the Sam Mendes-directed drama Revolutionary Road and appeared in the Ridley Scott-directed action film Body of Lies. DiCaprio reteamed with Scorsese in 2010 in the psychological thriller Shutter Island and also starred in the Christopher Nolan-directed science fiction heist thriller Inception. In 2011, he portrayed J. Edgar Hoover, the first director of the FBI, in the biopic J. Edgar. The following year, he played a supporting role in the Quentin Tarantino-directed western Django Unchained. DiCaprio starred in two film adaptations of novels in 2013; he first appeared as Jay Gatsby in the Luhrmann-directed adaptation of F. Scott Fitzgerald's novel The Great Gatsby, and later as Jordan Belfort in The Wolf of Wall Street, an adaptation of Belfort's memoir of the same name. The latter earned him a third Academy Award nomination for Best Actor and a Golden Globe Award for Best Actor – Motion Picture Musical or Comedy. In 2015, DiCaprio played fur trapper Hugh Glass in the survival drama The Revenant, for which he won the Academy Award for Best Actor.\n",
      "\n",
      "Page: Martin Scorsese and Leonardo DiCaprio\n",
      "Summary: Martin Scorsese and Leonardo DiCaprio are frequent collaborators in cinema, with DiCaprio appearing in six feature films and one short film made by Scorsese since 2002. The films explore a variety of genres, including historical epic, crime, thriller, biopic, comedy and western. Several have been listed on many critics' year-end top ten and best-of-decade lists.\n",
      "The duo's films have been nominated for thirty-one Academy Awards, winning nine. In 2013, the duo was awarded National Board of Review Spotlight award for career collaboration. Scorsese's work with DiCaprio is considered to be as vital as his work with Robert De Niro.\n",
      "\n",
      "Page: Leonardo DiCaprio\n",
      "Summary: Leonardo Wilhelm DiCaprio (, ; Italian: [diˈkaːprjo]; born November 11, 1974) i\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the year the film was released.\n",
      "Action: Calculator\n",
      "Action Input: 2006 raised to the 0.43 power\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 26.30281917656938\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The film Departed with Leonardo Dicaprio was released in 2006 and this year raised to the 0.43 power is 26.30281917656938.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The film Departed with Leonardo Dicaprio was released in 2006 and this year raised to the 0.43 power is 26.30281917656938.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run (\"In what year was the film Departed with Leonardo Dicaprio released? What is this year raised to the 0.43 powel?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Memory\n",
    "Add State to Chains and Agentsy\n",
    "Memory is the concept of persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of\n",
    "memory implementations, and examples of chains/agents that use memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! It's nice to meet you. How can I help you today?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "llm = OpenAI (temperature=0 )\n",
    "conversation = ConversationChain(llm=llm, verbose=True)\n",
    "conversation.predict (input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI:  Hi there! It's nice to meet you. How can I help you today?\n",
      "Human: Can we talk about AI?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Absolutely! What would you like to know about AI?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict (input=\"Can we talk about AI?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Document Loaders\n",
    "Combining language models with your own text data is a powerful way to differentiate them. The first step in doing this is to load the data into\n",
    "\"documents\" - a fancy way of say some pieces of text. This module is aimed at making this easy.\n",
    "https://python.langchain.com/en/latest/modules/indexes/document_loaders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader (\"Notion DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load ()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Indexes\n",
    "Indexes refer to ways to structure documents so that LLMs can best intera with them. This module contains utility functions for working with\n",
    "documents\n",
    "- Embeddings: An embedding is a numerical representation of a piece of information, for example, text, documents, images, audio, etc.\n",
    "- Text Splitters: When you want to deal with long pieces of text, it is necessary to split up that text into chunks.\n",
    "- Vectorstores: Vector databases store and index vector embeddings from NLP models to understand the meaning and context of strings\n",
    "of text, sentences, and whole documents for more accurate and relevant search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# url = \"https://raw.githubusercontent.com/hwchase17/langchain/master/docs/modules/state of the\n",
    "# res = requests.get(url)\n",
    "# with open(\"state of the unioh.txt\", \"w\") as f:\n",
    "# f.write(res.text)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
